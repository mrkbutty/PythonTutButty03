{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before continuing, please select menu option:  **Cell => All output => clear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open repo PythonTutButty03 and go through the CLI examples\n",
    "\n",
    " - CLIargs1.py - Parameter argv in the sys module.\n",
    " - CLIargs2.py - Program structure separating CLI parsing.\n",
    " - CLIargs3.py - separating options and arguments.\n",
    " - CLIskeleton.py - Uses argparse, a helpful python built-in module.\n",
    "\n",
    "Take a look at clickskeleton.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files & I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.exists('testdata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are many pathname manipulation functions:\n",
    " - https://docs.python.org/3/library/os.path.html\n",
    "  - Common ones are abspath, basename, dirname, exists, join, split, splitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(os.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir('testdata/') # old method no longer suggested to use (what if directory was huge)\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.scandir('testdata') # the preferred method\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.scandir('testdata'):\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "entries = Path('testdata')   # This is now the preferred method with most functionality\n",
    "for entry in entries.iterdir():\n",
    "    print(entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIX translate name patterns with wildcards like ? and * into a list of files. This is called globbing\n",
    "import glob\n",
    "glob.glob('testdata\\*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('.')\n",
    "list(p.glob('testdata\\*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walking a directory tree and printing the names of the directories and files\n",
    "count = 0\n",
    "for dirpath, dirnames, files in os.walk('.'):\n",
    "    count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a temporary file\n",
    "from tempfile import TemporaryFile\n",
    "fp = TemporaryFile('w+t')\n",
    "fp.write('Hello universe!')\n",
    "fp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()\n",
    "os.remove(fp.name)  # fails because the file was automatically removed upon closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('testdata/allconf.zip', 'r') as zipobj:\n",
    "    for i in zipobj.namelist():\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading & Writing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Modes are:\n",
    "- 'r'\topen for reading (default)\n",
    "- 'w'\topen for writing, truncating the file first\n",
    "- 'x'\topen for exclusive creation, failing if the file already exists\n",
    "- 'a'\topen for writing, appending to the end of the file if it exists\n",
    "- 'b'\tbinary mode\n",
    "- 't'\ttext mode (default)\n",
    "- '+'\topen a disk file for updating (reading and writing)\n",
    "- 'U'\tuniversal newlines mode (deprecated)\n",
    "\n",
    "Difference between binary/text:\n",
    "- Files opened in binary mode return contents as bytes objects without unicode decoding. \n",
    "- In text mode the contents of the file are returned as str, After the bytes are decoded using a platform-dependent or specified encoding.\n",
    "\n",
    "#### File methods:\n",
    " - `.read(size=-1)` Reads an entire file or up to *size* number of bytes.\n",
    " - `.readline(size=-1)` Reads the next line or up to *size* characters from the next line.\n",
    " - `.readlines=()` Reads the remaining lines from the file as a list (including '\\n').\n",
    " - `.write(string or bytes)` Writes to the file.\n",
    " - `.writelines(seq)` Writes the sequence to the file (note that line endings '\\n' are not appended).\n",
    " \n",
    " Note that the `print` statement also accepts a file object which can be an open file:\n",
    "     ```\n",
    "     print(*args, file=sys.stdout)\n",
    "     ```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfn = 'mytest.txt'\n",
    "fd = open(myfn, 'wb') # Note that mode of 'w' will open for writing and truncate the file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir my*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file mode used\n",
    "print(fd.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the files name\n",
    "print(fd.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write text to a file with a newline\n",
    "fd.write(bytes(\"Write me to the file\\n\", 'UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type mytest.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens a file for reading and writing\n",
    "fd = open(myfn, \"rb+\")  # the + indicates update mode, you can also write to it (no truncation)\n",
    "# Read text from the file\n",
    "text = fd.read()\n",
    "print(type(text))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implicitly closed before re-opening:\n",
    "fd = open(myfn, \"r+\")  # Note by default this is opened as text\n",
    "fd.seek(6)\n",
    "fd.write('XX')\n",
    "fd.seek(0)\n",
    "# Read text from the file\n",
    "text = fd.read()\n",
    "print(type(text))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the with statement context manager:\n",
    "with open(myfn, \"r+\") as fd:\n",
    "    # Read text from the file\n",
    "    text = fd.read()\n",
    "    print(type(text))\n",
    "    print(text)\n",
    "# file is automatically closed\n",
    "fd.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Delete the file\n",
    "os.remove(myfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir mytest.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking to see if the demo files are available with a Jupyter special execute prefix (!):\n",
    "!dir testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SSHOW_SYS.txt'\n",
    "filename = 'AllConf.csv'\n",
    "pathname = os.path.join('testdata', filename)\n",
    "if os.path.exists(pathname): print('Yes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pathname):\n",
    "    count = 0\n",
    "    with open(pathname) as fd:\n",
    "        line = fd.readline()\n",
    "        while line != '':  # The EOF is a n empty string\n",
    "            line=line.strip()\n",
    "            print(line)\n",
    "            count += 1\n",
    "            if count > 3: break\n",
    "            line = fd.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pathname):\n",
    "    count = 0\n",
    "    with open(pathname) as fd:\n",
    "        for line in fd.readlines():   # this will return a full list of the entire file\n",
    "            line=line.strip()   # Comment this line and see what happens\n",
    "            print(line)\n",
    "            count += 1\n",
    "            if count > 3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This final approach is more Pythonic and can be quicker and more memory efficient. \n",
    "# Therefore, it is suggested you use this instead.\n",
    "if os.path.exists(pathname):\n",
    "    with open(pathname) as fd:\n",
    "        for i, line in enumerate(fd):   # Notice how iterating over a file descriptor is same as issung .readline()\n",
    "            line = line.strip()\n",
    "            print(f'[{i}] {line}')\n",
    "            if i > 3: break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of opening a zip file and directly reading the internal file \n",
    "import zipfile\n",
    "with zipfile.ZipFile(r'testdata\\allconf.zip', 'r') as zipobj:\n",
    "    text = zipobj.read('AllConf.csv').decode()   # A zipfile object is opened as binary so may need decode to string \n",
    "\n",
    "for i, line in enumerate(text.split('\\n')):\n",
    "    print(line)\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with two files at once:\n",
    "There are times when you may want to read a file and write to another file at the same time. Here is an example:\n",
    "\n",
    "``` python\n",
    "d_path = 'dog_breeds.txt'\n",
    "d_r_path = 'dog_breeds_reversed.txt'\n",
    "with open(d_path, 'r') as reader, open(d_r_path, 'w') as writer:\n",
    "    dog_breeds = reader.readlines()\n",
    "    writer.writelines(reversed(dog_breeds))\n",
    "```\n",
    "\n",
    "### Don't reinvent the snake:\n",
    "Additionally, there are built-in libraries out there that you can use to help you:\n",
    "\n",
    "* wave: read and write WAV files (audio)\n",
    "* aifc: read and write AIFF and AIFC files (audio)\n",
    "* sunau: read and write Sun AU files\n",
    "* tarfile: read and write tar archive files\n",
    "* zipfile: work with ZIP archives\n",
    "* configparser: easily create and parse configuration files\n",
    "* xml.etree.ElementTree: create or read XML based files\n",
    "* msilib: read and write Microsoft Installer files\n",
    "* plistlib: generate and parse Mac OS X .plist files\n",
    "\n",
    "There are plenty more out there. Additionally there are even more third party tools available on PyPI. Some popular ones are the following:\n",
    "\n",
    "* PyPDF2: PDF toolkit\n",
    "* xlwings or : read and write Excel files\n",
    "* xlsxwriter : write Excel files\n",
    "* Pillow: image reading and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "1. In Vscode create a `mypackage` folder under the `pytut` directory (which you should have created previously).\n",
    "1. Copy all the `*.txt` `*.csv` files from PytutButty01 into this new directory.\n",
    "1. Copy the `CLIskeleton.py` (Under PytutButty03) program into this folder and rename it `mygrep.py`\n",
    "1. Write CLI program to accept a filename and text string:\n",
    "\n",
    "```\n",
    "mygrep.py [options] <filename> <text string>\n",
    "-c = case sensitive\n",
    "```\n",
    "\n",
    " - It needs to output any lines containing the text string.\n",
    " - By default supplied text searching should be case insensitive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (Part2):\n",
    "1. In the mypackage folder copy the `CLIskeleton.py` (Under PytutButty03) program into this folder and rename it `<name>tool.py`. \n",
    "1. You can play around & test in the notebook but the objecting is to do the following is a stand alone CLI program, so edit and modify the skeleton in Vscode:\n",
    "\n",
    "- Write some code to process either the `SSHOW_SYS.txt` or `Allconf.csv` or `poolinfo.txt` and print out your favorite section.\n",
    "    - `SSHOW_SYS.txt` example: text between `???/switchshow` to blank line.\n",
    "    - `Allconf.csv` example: text between `<<System Option Information>>` to next `<<?>>` section.\n",
    "    - `poolinfo.txt` example: text between `POOL-ID` and a blank line.\n",
    "\n",
    "### As a hint:\n",
    " - After the argparse processing call a new function `main(args.filename)`.\n",
    " - Create a new main function to process and output the file.\n",
    " - It can be a good idea to logically put in an output limit while initially developing (e.g. maximum 20 lines). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A (Very Brief) History of Regular Expressions\n",
    "\n",
    "In 1951, mathematician Stephen Cole Kleene described the concept of a regular language, a language that is recognizable by a finite automaton and formally expressible using regular expressions. In the mid-1960s, computer science pioneer Ken Thompson, one of the original designers of Unix, implemented pattern matching in the QED text editor using Kleene’s notation.\n",
    "\n",
    "Since then, regexes have appeared in many programming languages, editors, and other tools as a means of determining whether a string matches a specified pattern. Python, Java, and Perl all support regex functionality, as do most Unix tools and many text editors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Play around on https://pythex.org/, copy & paste below string test string:\n",
    "\n",
    "    The \"quick\" brown fox (may have jumped), [or not] over the lazy dog\"\n",
    "\n",
    "Hint: See the cheat sheet on the Pythex page.\n",
    "\n",
    "\n",
    "\n",
    "* Try searching for the letter \"o\".\n",
    "* Try searching for the word \"fox\".\n",
    "* Search for all whitespace\n",
    "* Search for all non-whitespace\n",
    "* Try searching for the word \"fox\" followed by \"dog\".\n",
    "* Try searching for a word with letter \"o\" or \"a\" in it.\n",
    "* Make groups of any word with an \"o\" in it.\n",
    "* Group words within []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings support some matching and searching functionaility:\n",
    "s = 'foo123bar'\n",
    "'123' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'foo123bar'\n",
    "s.find('123')\n",
    "# or\n",
    "s.index('123')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rather than searching for a fixed substring like '123', suppose you wanted to determine whether a string contains any three consecutive decimal digit characters, as in the strings 'foo123bar', 'foo456bar', '234baz', and 'qux678'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the \"re\" module from the python standard library:\n",
    "import re\n",
    "# dir(re) if you wish..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'foo123bar'\n",
    "re.search('\\d\\d\\d', s)   # produces a match object looking for 3 x digits\n",
    "# The span of the match object is the same as the slice in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.search('[0-9]{3}', s):   # a match object is truthy\n",
    "    print('Found a match')\n",
    "else:\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.match(r'\\d\\d\\d', s):   # If beginning of string match the regular expression pattern, return match object.\n",
    "    print('Found a match')\n",
    "else:\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above the use of r to denote a \"raw\" string, this is a common convention to avoid accidental interpretation.\n",
    "Unless an 'r' or 'R' prefix is present, escape sequences in string and bytes literals are interpreted according to rules similar to those used by Standard C. The recognized escape sequences are:\n",
    "```\n",
    "\\newline = Backslash and newline ignored\n",
    "\\\\ = Backslash (\\)\n",
    "\\' = Single quote (')\n",
    "\\\" = Double quote (\")\n",
    "\\a = ASCII Bell (BEL)\n",
    "\\b = ASCII Backspace (BS)\n",
    "\\f = ASCII Formfeed (FF)\n",
    "\\n = ASCII Linefeed (LF)\n",
    "\\r = ASCII Carriage Return (CR)\n",
    "\\t = ASCII Horizontal Tab (TAB)\n",
    "\\v = ASCII Vertical Tab (VT)\n",
    "\\ooo = Character with octal value ooo\n",
    "\\xhh = Character with hex value hh\n",
    "```\n",
    "\n",
    "Escape sequences only recognized in string literals are:\n",
    "```\n",
    "\\N{name} = Character named name in the Unicode database\n",
    "\\uxxxx = Character with 16-bit hex value xxxx\n",
    "\\Uxxxxxxxx = Character with 32-bit hex value xxxxxxxx\n",
    "```\n",
    "\n",
    "For example if looking for the newline character:\n",
    "```\n",
    "m = re.search(chr(92)+chr(110))\n",
    "m = re.search(\"\\\\n\")\n",
    "m = re.search(r\"\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use parenthesis to pull subgroups out of the string:\n",
    "s = 'foo123bar  foo bar'\n",
    "m = re.search(r'(\\d\\d\\d).*\\s+(\\w+)\\s+', s)\n",
    "if m:\n",
    "    print(m.groups())\n",
    "    print(m.group(0)) # The entire match\n",
    "    print(m.group(1)) # The first parenthesized subgroup\n",
    "    print(m.group(2)) # The second parenthesized subgroup\n",
    "    print(m.group(0,1,2)) # Multiple args give a tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What if we wanted the second subgroup above to pull out any characters not just alphanumeric (\\w)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sshow = '''Index Slot Port Address Media  Speed        State    Proto\n",
    "============================================================\n",
    "   0    3    0   720000   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "   1    3    1   720100   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "   2    3    2   720200   id    8G \t  Online      FC  F-Port  50:00:09:75:a8:17:50:1f \n",
    "   3    3    3   720300   id    8G \t  Online      FC  F-Port  50:00:09:75:a8:17:50:9f \n",
    "   4    3    4   720400   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "   5    3    5   720500   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "   8    3    8   720800   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "   9    3    9   720900   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "  10    3   10   720a00   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "  11    3   11   720b00   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "  12    3   12   720c00   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "  13    3   13   720d00   id    N32\t  No_Light    FC  Disabled (Persistent) \n",
    "  14    3   14   720e00   id    8G \t  Online      FC  F-Port  50:06:0e:80:12:3b:2c:13 \n",
    "  15    3   15   720f00   id    8G \t  Online      FC  LS E-Port  10:00:88:94:71:25:4b:43 \"sgsindcw03sanr02\" \n",
    "  16    3   16   721000   id    8G \t  Online      FC  F-Port  50:06:0e:80:07:c8:62:33 \n",
    "  17    3   17   721100   id    8G \t  Online      FC  F-Port  50:06:0e:80:07:c8:62:bb \n",
    "  18    3   18   721200   id    8G \t  Online      FC  F-Port  50:06:0e:80:07:29:83:13 \n",
    "  19    3   19   721300   id    8G \t  Online      FC  F-Port  50:06:0e:80:07:2a:84:13 \n",
    "  20    3   20   721400   id    8G \t  Online      FC  F-Port  50:06:0e:80:07:2a:fe:13 \n",
    "'''.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, for complex matches or many looped checks it is reccomended to `compile` to a regular expression pattern object before using for speed.\n",
    " - https://docs.python.org/3/library/re.html#regular-expression-objects\n",
    " - https://docs.python.org/3/library/re.html#match-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwnpat = re.compile(r'([0-9a-f][0-9a-f]([\\s:-]?[0-9a-f][0-9a-f]){7})', re.IGNORECASE)  # find wwn\n",
    "# all the re functions are also defined as pattern methods:\n",
    "for i, line in enumerate(sshow, 1):\n",
    "    m = wwnpat.search(line)\n",
    "    if m:\n",
    "        print(m.groups())\n",
    "        print(f'line{i}:', m.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwnpat = re.compile(r'([0-9a-f][0-9a-f]([\\s:-]?[0-9a-f][0-9a-f]){7})', re.IGNORECASE)  # find wwn\n",
    "# all the re functions are also defined as pattern methods:\n",
    "for i, line in enumerate(sshow, 1):\n",
    "    m = wwnpat.search(line)\n",
    "    if m:\n",
    "        print(re.split(r'\\s+', line))    # <== heres an example of spliting a string using regualr expressions\n",
    "        print(f'line{i}:', m.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "1. Have a scan of the re module: https://docs.python.org/3/library/re.html\n",
    "1. Create a function \"getcache\" to accept the list of cache lines.\n",
    " - Values should be stored in a list of dictionaries using the headers as a keys.\n",
    " - The function should return this list of dictionarys.\n",
    " - Note that headers and values are seperated by a mixture of `,+!@`\n",
    " - There is also a corrupt line which should be ignored.\n",
    " \n",
    "Goal is to return:\n",
    " \n",
    "```\n",
    "[{'Module#': '0',\n",
    "  'Cache Location': 'CACHE-1CA',\n",
    "  'CM DIMM Size(GB)': '32',\n",
    "  'Cache Size(GB)': '256',\n",
    "  'SM Size(GB)': '18',\n",
    "  'Cache Residency Size(MB)': '0',\n",
    "  'CFM Size(GB)': '400'},\n",
    " {'Module#': '0',\n",
    "  'Cache Location': 'CACHE-1CB',\n",
    "  'CM DIMM Size(GB)': '32',\n",
    "  'Cache Size(GB)': '160',\n",
    "  'SM Size(GB)': '',\n",
    "  'Cache Residency Size(MB)': '',\n",
    "  'CFM Size(GB)': '400'},\n",
    " {'Module#': '1',...\n",
    "    \n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It might be easier to copy paste this into https://pythex.org/ to test your regex:\n",
    "cache = '''<<Cache>>\n",
    "Module#,Cache Location,CM DIMM Size(GB)+Cache Size(GB)!SM Size(GB)@Cache Residency Size(MB),CFM Size(GB)\n",
    "0,CACHE-1CA,32,256,18,0,400\n",
    "0+CACHE-1CB+32+160+++400\n",
    "325$£%£$%\"£%\"£%%sfsdfsdf,sdfdsf£$234324234sdfdsfsd <= this is a data corruption\n",
    "1,CACHE-1CC,,,,,\n",
    "1,CACHE-1CD,,,,,\n",
    "0!CACHE-2CA!32!256!18!0!400\n",
    "0@CACHE-2CB@32@160@@@400\n",
    "1,\"CACHE-2CC\",,,,,\n",
    "1,\"CACHE-2CD\",,,,,'''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load answers/getcache.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "With what you have learned so far modify your tool program:\n",
    "1. Read in a file with the format of \"poolinfo.txt\" (i.e. passed on the command line)\n",
    "2. Make a dictionary of dictionarys for each Pool summary.\n",
    " - Key on the pool id.\n",
    " - Second level dictionary has key/value pairs for each item, e.g. `{'Type': 'DP(Multi-Tier)', 'Status':'Normal'}`.\n",
    "\n",
    "```\n",
    "    DP   <=== Note that each section: DP followed by multiple DP pools and TI by Thin Image pools.\n",
    "    DP(Multi-Tier)\n",
    "      POOL-ID : 0x0001(  1)   <=== KEY\n",
    "        Status                              : Normal\n",
    "        Total_Size                          : 232305528[MB]\n",
    "        Used_Size                           : 166673850[MB]\n",
    "        Reserved_Size                       : 0[MB]\n",
    "        Free_+_Reserved_Size(Formatted)     : 65631678[MB](22413426[MB])\n",
    "        Physical_Size                       : 0[MB]\n",
    "```\n",
    "        \n",
    "3. Add a two items to the dictionary to contain the POOL-VOL table.\n",
    " - Add a `poolvolheader` item for a list of headings.\n",
    " - Add a `poolvols` item to hold a list of lists containing the values.\n",
    " \n",
    " ```\n",
    "    POOL-VOL(136VOL(s))\n",
    "       Pool-Vol   Index   Tier   Volume_Size[MB]   Used_Size[MB]   Used_Rate[%]   Expanded_Space_Used   \n",
    "      ----------+-------+------+-----------------+---------------+--------------+---------------------+-\n",
    "       0xF000     0       1      2092944           1109262         53.0           Disabled              \n",
    "       0xF001     1       1      2097144           1111488         53.0           Disabled              \n",
    "       0xF002     2       1      2097144           1111488         53.0           Disabled              \n",
    "       0xF003     3       1      2097144           1111488         53.0           Disabled                        \n",
    "```\n",
    "\n",
    "\n",
    "4. Use the dictionary to print out statistics, e.g. line counts, value counts, max, min, total etc.\n",
    "\n",
    "#### Feel free to write & debug in Jupyter or Vscode but attempt to make a stand alone CLI program.\n",
    "#### I would suggest at least two functions; One or more producing the dictionary etc. and another to produce the statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators are great for processing files & pipelines\n",
    "\n",
    "*This example uses generator comprehensions but a more complete solution would likely use generator functions.*\n",
    "\n",
    "Imagine a large dataset:\n",
    "\n",
    "> permalink,company,numEmps,category,city,state,fundedDate,raisedAmt,raisedCurrency,round<br>\n",
    "> digg,Digg,60,web,San Francisco,CA,1-Dec-06,8500000,USD,b<br>\n",
    "> digg,Digg,60,web,San Francisco,CA,1-Oct-05,2800000,USD,a<br>\n",
    "> facebook,Facebook,450,web,Palo Alto,CA,1-Sep-04,500000,USD,angel<br>\n",
    "> facebook,Facebook,450,web,Palo Alto,CA,1-May-05,12700000,USD,a<br>\n",
    "> photobucket,Photobucket,60,web,Palo Alto,CA,1-Mar-05,3000000,USD,a<br>\n",
    "> ...\n",
    "\n",
    "Strategy:\n",
    "\n",
    "1. Read every line of the file.\n",
    "2. Split each line into a list of values.\n",
    "3. Extract the column names.\n",
    "4. Use the column names and lists to create a dictionary.\n",
    "5. Filter out the rounds you aren’t interested in.\n",
    "6. Calculate the total and average values for the rounds you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the sample available:\n",
    "!dir techcrunch.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type techcrunch.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file:\n",
    "file_name = \"techcrunch.csv\"\n",
    "lines = (line for line in open(file_name))\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each line ito values:\n",
    "list_line = (s.rstrip().split(\",\") for s in lines)\n",
    "list_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the header row:\n",
    "cols = next(list_line)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into a dictionary:\n",
    "company_dicts = (dict(zip(cols, data)) for data in list_line)\n",
    "company_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rounds you are not interested in:\n",
    "funding = (\n",
    "    int(company_dict[\"raisedAmt\"])\n",
    "    for company_dict in company_dicts\n",
    "    if company_dict[\"round\"].upper() == \"A\"\n",
    ")\n",
    "funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total:\n",
    "total_series_a = sum(funding)\n",
    "print(f\"Total series A fundraising: ${total_series_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    " 1. When does the code to read the data lines from the file get executed above?\n",
    " 2. Modify above to calcuate the average of the filtered rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
